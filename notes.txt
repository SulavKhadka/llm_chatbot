day to day tools that would help me:
- can you note this down: [link, text, screenshot, image]
- track this flight for me:
    - where is the flight going to X now?
    - how long till the x->Y plane lands?
    - where was the landing of the X flight again?
    - what airport did the flight coming into Y leave from?
- remind me about this thing/task
    - when? [specific time or datetime, approximate time(few hours, few days, etc) ]
    - whats it for? [this thing, dont worry about it]
- email inbox:
    - can you find the flight details regarding the SEA->IAD flight i have coming?
    - when was the last time i got an email about/from [brand, subject, flight, hotel booking, person, invitations]
    - How many unread emails do i have?
    - Did [person] email me yet?
    - Grab all the emails from [person/email] or about [subject]
    - Summarize this email chain for me
- Imessage:
    - Who just texted me?
    - Did [person] say anything about [subject]?
    - Has [person] seen my message?
    - what was the (auth)code that i just got sent for [company, tool, service]
    - can you let me know when [person, number] texts me?
    - tell me when [person, number] replies
    - will you text [person, number] saying [message]
- web search:
    - can you find out more about [topic, subject, person] so we can talk about it later

things needed:
- functionality for storing notes, reminders, performed actions
- way to notify/talk back to user for reminders or monitoring alerts
- agent tasks can be performed in various times of the conversations: 
    - realtime blocking: as the conversation is going, finishing task before moving to output or further processing.
    - concurrently: kick off the task in an async format and keep processing current input until results come back and gets mixed in before replying.
    - scheduled: doesnt need to happen right now, need to be done before next session or some other timeframe larger than the current turn/session.




             -> sys02: subconcious  -> 
user input -|
             -> sys01: concious     -> 


sys02:
- analysis:
    - what is this [input] asking?
    - what is the current context for this input? current conversation transcript + RAG_tool_call into previous conversations instances.
    - what do i need to know or am not confident about that i need to research to respond to this question? RAG_TOOL_CALL for external info


user_input
    -> tool_call: find relevant snippets from previous interactions
    -> sys02: internal yapping
        -> smol_model: what is this [input] asking?
        -> smol_model: what do I need to know or an not confident about in [input] that i need to research?




BUGS:
- sys message gets pasted twice
- if the system fails to response and we send another message, two user messages get added back to back, Need to add try catch and make the assistant response a internal error
- when loading a session state back after X time. the same openai_client might not be serving the backend(or shouldnt be required to) so instead of failing we should be able to switch over to the same model on a different provider or in the case of the model not being available across providers, continue on with one that is available.



metadata per message: this granularity is required to give the agent context of time and conversation patterns(maybe even let it decide how long it wants to wait to respond instead of always responding immediately)
    CURRENT_DATETIME
    OUTPUT_MODALITY (for assistant responses)
    INPUT_MODALITY (for user inputs)


Can the bot handle this scenario?
- for the next hour, every 5 mins, get the current weather and wind conditions and then alert me only if the wind is blowing above 10mph and temp is below 50F.
    - this needs to track and have a non user trigger to the bot loop, as well as an option to not respond until a crietria is met.

Voice Mode:
- If asked for code or something like that, we still output it but for voice output filter that out so it doesnt go over TTS but tells user to refer to a screen(chat window) for the code.
- 

- Need 

U: hey can you help me plan my day, whats the weather and if i have any appointments let me know what the weather are for the ones i need to go out for
A: <t>i need to see what tools can help me assist the user. I would need tools for getting the days weather forecast ideally by the hour, access to the calendar where the user has their appointments for the day, which i can then combine to see if any appointments leave the house and see the corresponding weather at that time to advise the user.<t><tool_call>[{"name": "", "parameters": ""}]</tool_call>


how to test computer control and screenshot and other local features
- screenshot and browser control can be tested by launching a browser then displaying certain test images, screenshoting then asking vlm for answers to the questions as a way to test multiple things at once.(need to carefully think about how one effects the other)
- not sure how to test computer control

Problem:
- If i am talking from tts bot to it(which means a session is open for that and has been loaded to the chatbot class instance) and i switch to the same session in chatbot window and add a message continuing the conversation there, how will the tts_bot know there have been state updates to the db and that it needs to sync again?
    - I think we need to be relying on db always even in a instatiated chatbot instance
    - make the session state in a redis instance type thing and refresh storage for any DB activity on the tracked sessions: this captures multi device updates. 
    - a global session keeper sounds like a good way to do sync across devices and users although we are only focused on devices at the moment